{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from proj1_helpers import *\n",
    "from data_cleaning import *\n",
    "import implementations as imp\n",
    "import plots\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "COLUMN_TO_DROP = 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, x_train, ids_train = load_csv_data(\"../data/train.csv\")\n",
    "y_test, x_test, ids_test = load_csv_data(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 30)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data and add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1 1 ... 1 0 0]]\n",
      "(250000, 29)\n",
      "0.4736512480675119\n",
      "(250000, 29)\n"
     ]
    }
   ],
   "source": [
    "NUM_JETS = 4\n",
    "\n",
    "PRI_jet_num_train = np.array([x_train[:, COLUMN_TO_DROP]]).astype(int)\n",
    "print(PRI_jet_num_train)\n",
    "del_x_train = np.delete(x_train, COLUMN_TO_DROP, axis=1)\n",
    "print(del_x_train.shape)\n",
    "\n",
    "replaced_x_train = replace_undefined_with_mean(del_x_train, UNDEFINED_VALUE)\n",
    "\n",
    "norm_x_train, train_data_mean, train_data_std = mean_std_normalization(replaced_x_train)\n",
    "\n",
    "print(norm_x_train[0][0])\n",
    "print(norm_x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the same for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ... 0 1 0]]\n",
      "(1, 568238)\n",
      "(568238, 29)\n",
      "46.72265694612496\n",
      "(568238, 29)\n"
     ]
    }
   ],
   "source": [
    "PRI_jet_num_test = np.array([x_test[:, COLUMN_TO_DROP]]).astype(int)\n",
    "print(PRI_jet_num_test)\n",
    "print(PRI_jet_num_test.shape)\n",
    "del_x_test = np.delete(x_test, COLUMN_TO_DROP, axis=1)\n",
    "print(del_x_test.shape)\n",
    "\n",
    "replaced_x_test = replace_undefined_with_mean(del_x_test, UNDEFINED_VALUE)\n",
    "\n",
    "norm_x_test, test_data_mean, test_data_std = mean_std_normalization(replaced_x_test, train_data_mean, train_data_std)\n",
    "print(norm_x_test[0][0])\n",
    "print(norm_x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make and train model\n",
    "### GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 loss=1.0\n",
      "Iteration 1 loss=1.4885054938929285\n",
      "Iteration 2 loss=2.215648605349431\n",
      "Iteration 3 loss=3.2980051215988344\n",
      "Iteration 4 loss=4.909098742386882\n",
      "Iteration 5 loss=7.307220448105742\n",
      "Iteration 6 loss=10.876837782092146\n",
      "Iteration 7 loss=16.190232794826333\n",
      "Iteration 8 loss=24.099250462504457\n",
      "Iteration 9 loss=35.87186671213957\n",
      "Iteration 10 loss=53.395470677214604\n",
      "Iteration 11 loss=79.4794514520327\n",
      "Iteration 12 loss=118.30560013794695\n",
      "Iteration 13 loss=176.098535763634\n",
      "Iteration 14 loss=262.1236379506695\n",
      "Iteration 15 loss=390.1724751687724\n",
      "Iteration 16 loss=580.7738728545197\n",
      "Iteration 17 loss=864.4851004534258\n",
      "Iteration 18 loss=1286.790821413505\n",
      "Iteration 19 loss=1915.3952071649967\n",
      "Iteration 20 loss=2851.076288841281\n",
      "Iteration 21 loss=4243.842719448107\n",
      "Iteration 22 loss=6316.983203116015\n",
      "Iteration 23 loss=9402.864202667537\n",
      "Iteration 24 loss=13996.21502399978\n",
      "Iteration 25 loss=20833.442956930423\n",
      "Iteration 26 loss=31010.694298095874\n",
      "Iteration 27 loss=46159.58883214982\n",
      "Iteration 28 loss=68708.80157249366\n",
      "Iteration 29 loss=102273.4286194559\n",
      "Iteration 30 loss=152234.56037932634\n",
      "Iteration 31 loss=226601.97948500197\n",
      "Iteration 32 loss=337298.2913904381\n",
      "Iteration 33 loss=502070.359815365\n",
      "Iteration 34 loss=747334.4889059704\n",
      "Iteration 35 loss=1112411.492512201\n",
      "Iteration 36 loss=1655830.6180740434\n",
      "Iteration 37 loss=2464712.9719593367\n",
      "Iteration 38 loss=3668738.7996306396\n",
      "Iteration 39 loss=5460937.858908354\n",
      "Iteration 40 loss=8128636.004792969\n",
      "Iteration 41 loss=12099519.350990197\n",
      "Iteration 42 loss=18010201.02741271\n",
      "Iteration 43 loss=26808283.175419867\n",
      "Iteration 44 loss=39904276.788449824\n",
      "Iteration 45 loss=59397735.22943163\n",
      "Iteration 46 loss=88413855.21380651\n",
      "Iteration 47 loss=131604509.22200489\n",
      "Iteration 48 loss=195894034.99803683\n",
      "Iteration 49 loss=291589347.31543136\n",
      "Iteration 50 loss=434032345.43967277\n",
      "Iteration 51 loss=646059530.7141861\n",
      "Iteration 52 loss=961663160.8499528\n",
      "Iteration 53 loss=1431440898.199593\n",
      "Iteration 54 loss=2130707641.1531224\n",
      "Iteration 55 loss=3171570029.736065\n",
      "Iteration 56 loss=4720899413.528291\n",
      "Iteration 57 loss=7027084713.152766\n",
      "Iteration 58 loss=10459854201.578907\n",
      "Iteration 59 loss=15569550444.369238\n",
      "Iteration 60 loss=23175361373.886703\n",
      "Iteration 61 loss=34496652727.98433\n",
      "Iteration 62 loss=51348457106.521164\n",
      "Iteration 63 loss=76432460505.98212\n",
      "Iteration 64 loss=113770137374.90865\n",
      "Iteration 65 loss=169347474523.50473\n",
      "Iteration 66 loss=252074646205.12955\n",
      "Iteration 67 loss=375214495747.4515\n",
      "Iteration 68 loss=558508838308.3463\n",
      "Iteration 69 loss=831343474209.731\n",
      "Iteration 70 loss=1237459328673.219\n",
      "Iteration 71 loss=1841965009199.1414\n",
      "Iteration 72 loss=2741775035751.46\n",
      "Iteration 73 loss=4081147203734.529\n",
      "Iteration 74 loss=6074810034144.607\n",
      "Iteration 75 loss=9042388110180.137\n",
      "Iteration 76 loss=13459644379915.229\n",
      "Iteration 77 loss=20034754605348.9\n",
      "Iteration 78 loss=29821842298858.48\n",
      "Iteration 79 loss=44389976099859.35\n",
      "Iteration 80 loss=66074723298416.43\n",
      "Iteration 81 loss=98352588637147.97\n",
      "Iteration 82 loss=146398368524985.97\n",
      "Iteration 83 loss=217914775846403.16\n",
      "Iteration 84 loss=324367341047817.1\n",
      "Iteration 85 loss=482822569189117.06\n",
      "Iteration 86 loss=718684046813499.5\n",
      "Iteration 87 loss=1069765152055096.6\n",
      "Iteration 88 loss=1592351306009214.8\n",
      "Iteration 89 loss=2370223667202295.5\n",
      "Iteration 90 loss=3528090950385661.5\n",
      "Iteration 91 loss=5251582762602981.0\n",
      "Iteration 92 loss=7817009793767941.0\n",
      "Iteration 93 loss=1.1635662023838406e+16\n",
      "Iteration 94 loss=1.7319746847564782e+16\n",
      "Iteration 95 loss=2.5780538335434908e+16\n",
      "Iteration 96 loss=3.837447294781211e+16\n",
      "Iteration 97 loss=5.712061380806391e+16\n",
      "Iteration 98 loss=8.50243474678394e+16\n",
      "Iteration 99 loss=1.2655920832054022e+17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2655920832054022e+17"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = 0.1\n",
    "max_iters = 100\n",
    "#_, initial_w = imp.least_squares(y_train, norm_x_train)\n",
    "initial_w = np.zeros(norm_x_train.shape[1], dtype=np.float64)\n",
    "seed = 1\n",
    "ratio = 0.5\n",
    "(tr_x, tr_y, te_x,te_y) = split_data(norm_x_train, y_train, ratio, seed)\n",
    "gd_loss, gd_weights = imp.least_squares_SGD(tr_y, tr_x, initial_w, max_iters, gamma)\n",
    "gd_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.614352"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validation = predict_labels(gd_weights, te_x)\n",
    "score = sum(y_validation == te_y)/len(te_y)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with degree = 2\n",
      "Running with degree = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python_workspace\\school\\CourseMachineLearning\\Project\\CS-433---Machine-Learning\\project1\\scripts\\proj1_helpers.py:30: RuntimeWarning: invalid value encountered in less_equal\n",
      "  y_pred[np.where(y_pred <= 0)] = -1\n",
      "D:\\python_workspace\\school\\CourseMachineLearning\\Project\\CS-433---Machine-Learning\\project1\\scripts\\proj1_helpers.py:31: RuntimeWarning: invalid value encountered in greater\n",
      "  y_pred[np.where(y_pred > 0)] = 1\n",
      "D:\\python_workspace\\school\\CourseMachineLearning\\Project\\CS-433---Machine-Learning\\project1\\scripts\\implementations.py:94: RuntimeWarning: invalid value encountered in subtract\n",
      "  w = w - (grad*gamma)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with degree = 4\n",
      "Running with degree = 5\n",
      "Running with degree = 6\n",
      "Running with degree = 7\n",
      "Running with degree = 8\n",
      "Running with degree = 9\n",
      "Running with degree = 10\n",
      "Running with degree = 11\n",
      "Running with degree = 12\n",
      "Running with degree = 13\n",
      "Running with degree = 14\n"
     ]
    }
   ],
   "source": [
    "gamma_list = [0.0001,0.001, 0.01, 0.1]\n",
    "degree_list = range(2,15)\n",
    "max_iters = 100\n",
    "seed = 1\n",
    "ratio = 0.8\n",
    "\n",
    "best_gamma = np.zeros(4)\n",
    "best_score = np.zeros(4)\n",
    "best_degree = np.zeros(4)\n",
    "all_scores = np.zeros([len(gamma_list), len(degree_list)])\n",
    "g = 0\n",
    "d = 0\n",
    "\n",
    "\n",
    "for degree in degree_list:\n",
    "    print(\"Running with degree = {}\".format(degree))\n",
    "    for i in range(NUM_JETS):\n",
    "        curr_x = norm_x_train[PRI_jet_num_train[0,:]==i]\n",
    "        curr_y = y_train[PRI_jet_num_train[0,:]==i]\n",
    "        \n",
    "        (tr_x, tr_y, te_x,te_y) = split_data(curr_x, curr_y, ratio, seed)\n",
    "        \n",
    "        px_tr = create_poly_features(tr_x, degree)\n",
    "        px_te = create_poly_features(te_x, degree)\n",
    "        \n",
    "        initial_w = np.zeros(px_tr.shape[1], dtype=np.float64)\n",
    "        \n",
    "        g = 0\n",
    "        for gamma in gamma_list:\n",
    "\n",
    "            gd_loss, gd_weights = imp.least_squares_GD(tr_y, px_tr, initial_w, max_iters, gamma)\n",
    "\n",
    "            y_validation = predict_labels(gd_weights, px_te)\n",
    "            score = sum(y_validation == te_y)/len(te_y)\n",
    "\n",
    "            if score > best_score[i]:\n",
    "                best_gamma[i] = gamma\n",
    "                best_degree[i] = degree\n",
    "                best_score[i] = score\n",
    "            all_scores[g,d] = all_scores[g,d] + score*sum(PRI_jet_num_train[0,:]==i)/len(norm_x_train)\n",
    "            g = g+1\n",
    "    d = d+1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7656847279875\n"
     ]
    }
   ],
   "source": [
    "#calc actual score\n",
    "actual_score = 0\n",
    "for i in range(NUM_JETS):\n",
    "    actual_score = actual_score + best_score[i]*sum(PRI_jet_num_train[0,:]==i)/len(norm_x_train)\n",
    "\n",
    "print(actual_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma=[0.01  0.01  0.001 0.001]\n",
      "Degree=[2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Gamma=\" + str(best_gamma))\n",
    "print(\"Degree=\" + str(best_degree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.1\n",
    "max_iters = 50\n",
    "initial_w = np.zeros(new_x_train.shape[1], dtype=np.float64)\n",
    "batch_size = int(np.floor(new_x_train.shape[0] / 100))\n",
    "\n",
    "# Training\n",
    "sgd_loss, sgd_weights = imp.least_squares_SGD(y_train, new_x_train, initial_w, max_iters, gamma, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.subplots(figsize=(20,10))\n",
    "plt.plot(sgd_loss)\n",
    "plt.legend([\"Training loss\"])\n",
    "plt.grid()\n",
    "plt.title(\"Loss for Stochastic Gradient Decent\")\n",
    "plt.xlabel(\"Iteration number\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_labels(sgd_weights[-1], new_x_test)\n",
    "n = len(y_pred)\n",
    "correct = 0\n",
    "for i in range(n):\n",
    "    if (y_pred[i] == y_test[i]):\n",
    "        correct += 1\n",
    "print(str(correct) + \" of \" + str(n) + \" correct, precentage: \" + str(correct/n)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(y, tx, initial_w, max_iters, gamma):\n",
    "\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    loss = 0\n",
    "    #threshold = 1e-8\n",
    "    for n_iter in range(max_iters):\n",
    "        loss = sum(sum(np.logaddexp(0, tx.dot(w)) - y*(tx.dot(w))))\n",
    "        prediction = sigmoid(tx.dot(w))\n",
    "        gradient = tx.T.dot(prediction - y)\n",
    "\n",
    "        # gradient w by descent update\n",
    "        w = w - (gamma * gradient)\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "\n",
    "        #if (len(losses) > 1 and np.abs(losses[-1] - losses[-2]) < threshold):\n",
    "        #   break\n",
    "\n",
    "    #finds best parameters\n",
    "    min_ind = np.argmin(losses)\n",
    "    loss = losses[min_ind]\n",
    "    w = ws[min_ind][:]\n",
    "    \n",
    "    return w, loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
